
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Index - é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#fine-tuning-your-llm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" class="md-header__button md-logo" aria-label="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Index
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" class="md-nav__button md-logo" aria-label="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è¯¾ç¨‹ ( Version 3 )
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../00-course-setup/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    è¯¾ç¨‹ä»‹ç»å’Œå­¦ä¹ ç¯å¢ƒè®¾ç½®
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-introduction-to-genai/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸€ç«  : ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å’Œ LLMs ä»‹ç»
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-exploring-and-comparing-different-llms/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬äºŒç«  : æ¢ç´¢å’Œæ¯”è¾ƒä¸åŒçš„ LLMs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-using-generative-ai-responsibly/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸‰ç«  ï¼š è´Ÿè´£ä»»åœ°ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-prompt-engineering-fundamentals/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å››ç« ï¼šæç¤ºå·¥ç¨‹åŸºç¡€
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-advanced-prompts/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬äº”ç« ï¼šåˆ›å»ºé«˜çº§çš„æç¤ºå·¥ç¨‹æŠ€å·§
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-text-generation-apps/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å…­ç« ï¼šåˆ›å»ºæ–‡æœ¬ç”Ÿæˆåº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-building-chat-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸ƒç« ï¼šåˆ›å»ºèŠå¤©åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-building-search-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å…«ç« ï¼šåˆ›å»ºæœç´¢åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-building-image-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¹ç« ï¼šæ„å»ºå›¾åƒç”Ÿæˆåº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-building-low-code-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åç« ï¼šåˆ›å»ºä½ä»£ç çš„äººå·¥æ™ºèƒ½åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../11-integrating-with-function-calling/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åä¸€ç« ï¼šä¸ºç”Ÿæˆå¼ AI æ·»åŠ  function calling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-designing-ux-for-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åäºŒç« ï¼šä¸ºäººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºæ·»åŠ ç”¨æˆ·ä½“éªŒ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../13-securing-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç”Ÿæˆå¼ AI åˆå­¦è€…æŒ‡å—ï¼šç¬¬ 13 ç«  - ä¿æŠ¤ AI åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../14-the-generative-ai-application-lifecycle/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../15-rag-and-vector-databases/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä¸å‘é‡æ•°æ®åº“
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../16-open-source-models/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../17-ai-agents/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../19-slm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Small Language Models for Generative AI for Beginners
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../20-mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building with Mistral Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../21-meta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building With the Meta Family Models
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#illustrated-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Illustrated Guide
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-is-fine-tuning-for-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      What is fine-tuning for language models?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-and-why-should-we-fine-tune-models" class="md-nav__link">
    <span class="md-ellipsis">
      When and why should we fine-tune models?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-we-fine-tune-a-pre-trained-model" class="md-nav__link">
    <span class="md-ellipsis">
      How can we fine-tune a pre-trained model?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tuning-in-action" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-Tuning In Action
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assignment" class="md-nav__link">
    <span class="md-ellipsis">
      Assignment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#great-work-continue-your-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Great Work! Continue Your Learning.
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst"><img alt="Open Source Models" src="img/18-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<h1 id="fine-tuning-your-llm">Fine-Tuning Your LLM</h1>
<p>Using large language models to build generative AI applications comes with new challenges. A key issue is ensuring response quality (accuracy and relevance) in content generated by the model for a given user request. In previous lessons, we discussed techniques like prompt engineering and retrieval-augmented generation that try to solve the problem by <em>modifying the prompt input</em> to the existing model.</p>
<p>In today's lesson, we discuss a third technique, <strong>fine-tuning</strong>, which tries to address the challenge by <em>retraining the model itself</em> with additional data. Let's dive into the details.</p>
<h2 id="learning-objectives">Learning Objectives</h2>
<p>This lesson introduces the concept of fine-tuning for pre-trained language models, explores the benefits and challenges of this approach, and provides guidance on when and how to use fine tuning to improve the performance of your generative AI models.</p>
<p>By the end of this lesson, you should be able to answer the following questions:</p>
<ul>
<li>What is fine tuning for language models?</li>
<li>When, and why, is fine tuning useful?</li>
<li>How can I fine-tune a pre-trained model?</li>
<li>What are the limitations of fine-tuning?</li>
</ul>
<p>Ready? Let's get started.</p>
<h2 id="illustrated-guide">Illustrated Guide</h2>
<p>Want to get the big picture of what we'll cover before we dive in? Check out this illustrated guide that describes the learning journey for this lesson - from learning the core concepts and motivation for fine-tuning, to understanding the process and best practices for executing the fine-tuning task. This is a fascinating topic for exploration, so don't forget to check out the <a href="RESOURCES/?WT.mc_id=academic-105485-koreyst">Resources</a> page for additional links to support your self-guided learning journey!</p>
<p><img alt="Illustrated Guide to Fine Tuning Language Models" src="img/18-fine-tuning-sketchnote.png?WT.mc_id=academic-105485-koreyst" /></p>
<h2 id="what-is-fine-tuning-for-language-models">What is fine-tuning for language models?</h2>
<p>By definition, large language models are <em>pre-trained</em> on large quantities of text sourced from diverse sources including the internet. As we've learned in previous lessons, we need techniques like <em>prompt engineering</em> and <em>retrieval-augmented generation</em> to improve the quality of the model's responses to the user's questions ("prompts").</p>
<p>A popular prompt-engineering technique involves giving the model more guidance on what is expected in the response either by providing <em>instructions</em> (explicit guidance) or <em>giving it a few examples</em> (implicit guidance). This is referred to as <em>few-shot learning</em> but it has two limitations:</p>
<ul>
<li>Model token limits can restrict the number of examples you can give, and limit the effectiveness.</li>
<li>Model token costs can make it expensive to add examples to every prompt, and limit flexibility.</li>
</ul>
<p>Fine-tuning is a common practice in machine learning systems where we take a pre-trained model and retrain it with new data to improve its performance on a specific task. In the context of language models, we can fine-tune the pre-trained model <em>with a curated set of examples for a given task or application domain</em> to create a <strong>custom model</strong> that may be more accurate and relevant for that specific task or domain. A side-benefit of fine-tuning is that it can also reduce the number of examples needed for few-shot learning - reducing token usage and related costs.</p>
<h2 id="when-and-why-should-we-fine-tune-models">When and why should we fine-tune models?</h2>
<p>In <em>this</em> context, when we talk about fine-tuning, we are referring to <strong>supervised</strong> fine-tuning where the retraining is done by <strong>adding new data</strong> that was not part of the original training dataset. This is different from an unsupervised fine-tuning approach where the model is retrained on the original data, but with different hyperparameters.</p>
<p>The key thing to remember is that fine-tuning is an advanced technique that requires a certain level of expertise to get the desired results. If done incorrectly, it may not provide the expected improvements, and may even degrade the performance of the model for your targeted domain.</p>
<p>So, before you learn "how" to fine-tune language models, you need to know "why" you should take this route, and "when" to start the process of fine-tuning. Start by asking yourself these questions:</p>
<ul>
<li><strong>Use Case</strong>: What is your <em>use case</em> for fine-tuning? What aspect of the current pre-trained model do you want to improve upon?</li>
<li><strong>Alternatives</strong>: Have you tried <em>other techniques</em> to achieve the desired outcomes? Use them to create a baseline for comparison.</li>
<li>Prompt engineering: Try techniques like few-shot prompting with examples of relevant prompt responses. Evaluate the quality of responses.</li>
<li>Retrieval Augmented Generation: Try augmenting prompts with query results retrieved by searching your data. Evaluate the quality of responses.</li>
<li><strong>Costs</strong>: Have you identified the costs for fine-tuning?</li>
<li>Tunability - is the pre-trained model available for fine-tuning?</li>
<li>Effort - for preparing training data, evaluating &amp; refining model.</li>
<li>Compute - for running fine-tuning jobs, and deploying fine-tuned model</li>
<li>Data - access to sufficient quality examples for fine-tuning impact</li>
<li><strong>Benefits</strong>: Have you confirmed the benefits for fine-tuning?</li>
<li>Quality - did fine-tuned model outperform baseline?</li>
<li>Cost - does it reduce token usage by simplifying prompts?</li>
<li>Extensibility - can you repurpose base model for new domains?</li>
</ul>
<p>By answering these questions, you should be able to decide if fine-tuning is the right approach for your use case. Ideally, the approach is valid only if the benefits outweigh the costs. Once you decide to proceed, it's time to think about <em>how</em> you can fine tune the pre-trained model.</p>
<p>Want to get more insights on the decision-making process? Watch <a href="https://www.youtube.com/watch?v=0Jo-z-MFxJs">To fine-tune or not to fine-tune</a></p>
<h2 id="how-can-we-fine-tune-a-pre-trained-model">How can we fine-tune a pre-trained model?</h2>
<p>To fine-tune a pre-trained model, you need to have:</p>
<ul>
<li>a pre-trained model to fine-tune</li>
<li>a dataset to use for fine-tuning</li>
<li>a training environment to run the fine-tuning job</li>
<li>a hosting environment to deploy fine-tuned model</li>
</ul>
<h2 id="fine-tuning-in-action">Fine-Tuning In Action</h2>
<p>The following resources provide step-by-step tutorials to walk you through a real example using a selected model with a curated dataset. To work through these tutorials, you need an account on the specific provider, along with access to the relevant model and datasets.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Tutorial</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpenAI</td>
<td><a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst">How to fine-tune chat models</a></td>
<td>Learn to fine-tune a <code>gpt-35-turbo</code> for a specific domain ("recipe assistant") by preparing training data, running the fine-tuning job, and using the fine-tuned model for inference.</td>
</tr>
<tr>
<td>Azure OpenAI</td>
<td><a href="https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst">GPT 3.5 Turbo fine-tuning tutorial</a></td>
<td>Learn to fine-tune a <code>gpt-35-turbo-0613</code> model <strong>on Azure</strong> by taking steps to create &amp; upload training data, run the fine-tuning job. Deploy &amp; use the new model.</td>
</tr>
<tr>
<td>Hugging Face</td>
<td><a href="https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst">Fine-tuning LLMs with Hugging Face</a></td>
<td>This blog post walks you fine-tuning an <em>open LLM</em> (ex: <code>CodeLlama 7B</code>) using the <a href="https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst">transformers</a> library &amp; <a href="https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]">Transformer Reinforcement Learning (TRL)</a> with open <a href="https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst">datasets</a> on Hugging Face.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ğŸ¤— AutoTrain</td>
<td><a href="https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst">Fine-tuning LLMs with AutoTrain</a></td>
<td>AutoTrain (or AutoTrain Advanced) is a python library developed by Hugging Face that allows finetuning for many different tasks including LLM finetuning. AutoTrain is a no-code solution and finetuning can be done in your own cloud, on Hugging Face Spaces or locally. It supports both a web-based GUI, CLI and training via yaml config files.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="assignment">Assignment</h2>
<p>Select one of the tutorials above and walk through them. <em>We may replicate a version of these tutorials in Jupyter Notebooks in this repo for reference only. Please use the original sources directly to get the latest versions</em>.</p>
<h2 id="great-work-continue-your-learning">Great Work! Continue Your Learning.</h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>
<p>Congratulations!! You have completed the final lesson from the v2 series for this course! Don't stop learning and building. **Check out the <a href="RESOURCES/?WT.mc_id=academic-105485-koreyst">RESOURCES</a> page for a list of additional suggestions for just this topic.</p>
<p>Our v1 series of lessons have also been updated with more assignments and concepts. So take a minute to refresh your knowledge - and please <a href="https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst">share your questions and feedback</a> to help us improve these lessons for the community.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>