
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Retrieval Augmented Generation (RAG) and Vector Databases - 面向初学者的生成式AI课程</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#retrieval-augmented-generation-rag-and-vector-databases" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="面向初学者的生成式AI课程" class="md-header__button md-logo" aria-label="面向初学者的生成式AI课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            面向初学者的生成式AI课程
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Retrieval Augmented Generation (RAG) and Vector Databases
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="面向初学者的生成式AI课程" class="md-nav__button md-logo" aria-label="面向初学者的生成式AI课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    面向初学者的生成式AI课程
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向初学者的生成式人工智能课程 ( Version 3 )
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../00-course-setup/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课程介绍和学习环境设置
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-introduction-to-genai/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第一章 : 生成式人工智能和 LLMs 介绍
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-exploring-and-comparing-different-llms/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第二章 : 探索和比较不同的 LLMs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-using-generative-ai-responsibly/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第三章 ： 负责任地使用生成式人工智能
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-prompt-engineering-fundamentals/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第四章：提示工程基础
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-advanced-prompts/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第五章：创建高级的提示工程技巧
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-text-generation-apps/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第六章：创建文本生成应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-building-chat-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第七章：创建聊天应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-building-search-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第八章：创建搜索应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-building-image-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第九章：构建图像生成应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-building-low-code-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十章：创建低代码的人工智能应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../11-integrating-with-function-calling/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十一章：为生成式 AI 添加 function calling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-designing-ux-for-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十二章：为人工智能应用程序添加用户体验
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../13-securing-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成式 AI 初学者指南：第 13 章 - 保护 AI 应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../14-the-generative-ai-application-lifecycle/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    检索增强生成 (RAG) 与向量数据库
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../16-open-source-models/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../17-ai-agents/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../18-fine-tuning/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../19-slm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Small Language Models for Generative AI for Beginners
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../20-mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building with Mistral Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../21-meta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building With the Meta Family Models
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-goals" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Goals
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#our-scenario-enhancing-our-llms-with-our-own-data" class="md-nav__link">
    <span class="md-ellipsis">
      Our Scenario: enhancing our LLMs with our own data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#retrieval-augmented-generation-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval Augmented Generation (RAG)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Retrieval Augmented Generation (RAG)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-rags-retrieval-augmented-generation-work" class="md-nav__link">
    <span class="md-ellipsis">
      How RAGs (Retrieval Augmented Generation) work
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-would-you-use-rags" class="md-nav__link">
    <span class="md-ellipsis">
      Why would you use RAGs?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#creating-a-knowledge-base" class="md-nav__link">
    <span class="md-ellipsis">
      Creating a knowledge base
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Creating a knowledge base">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vector-databases" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Databases
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-text-to-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      From text to embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#retrieval-and-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval and Vector Search
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Retrieval and Vector Search">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#search-index" class="md-nav__link">
    <span class="md-ellipsis">
      Search index
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#re-ranking" class="md-nav__link">
    <span class="md-ellipsis">
      Re-ranking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bringing-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      Bringing it all together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-our-application" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluating our application
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluating our application">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation Metrics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#use-cases-for-using-rag-retervival-augmented-generation-and-vector-databases" class="md-nav__link">
    <span class="md-ellipsis">
      Use Cases for using RAG (Retervival Augmented Generation) and vector databases
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assignment" class="md-nav__link">
    <span class="md-ellipsis">
      Assignment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-does-not-stop-here-continue-the-journey" class="md-nav__link">
    <span class="md-ellipsis">
      Learning does not stop here, continue the Journey
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="retrieval-augmented-generation-rag-and-vector-databases">Retrieval Augmented Generation (RAG) and Vector Databases</h1>
<p><a href="https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst"><img alt="Retrieval Augmented Generation (RAG) and Vector Databases" src="images/15-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<p>In the search applications lesson, we briefly learned how to integrate your own data into Large Language Models (LLMs). In this lesson, we will delve further into the concepts of grounding your data in your LLM application, the mechanics of the process and the methods for storing data, including both embeddings and text.</p>
<blockquote>
<p><strong>Video Coming Soon</strong></p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>In this lesson we will cover the following:</p>
<ul>
<li>
<p>An introduction to RAG, what it is and why it is used in AI (artificial intelligence).</p>
</li>
<li>
<p>Understanding what vector databases are and creating one for our application.</p>
</li>
<li>
<p>A practical example on how to integrate RAG into an application.</p>
</li>
</ul>
<h2 id="learning-goals">Learning Goals</h2>
<p>After completing this lesson, you will be able to:</p>
<ul>
<li>
<p>Explain the significance of RAG in data retrieval and processing.</p>
</li>
<li>
<p>Setup RAG application and ground your data to an LLM</p>
</li>
<li>
<p>Effective integration of RAG and Vector Databases in LLM Applications.</p>
</li>
</ul>
<h2 id="our-scenario-enhancing-our-llms-with-our-own-data">Our Scenario: enhancing our LLMs with our own data</h2>
<p>For this lesson, we want to add our own notes into the education startup, which allows the chatbot to get more information on the different subjects. Using the notes that we have, learners will be able to study better and understand the different topics, making it easier to revise for their examinations. To create our scenario, we will use:</p>
<ul>
<li>
<p><code>Azure OpenAI:</code> the LLM we will use to create our chatbot</p>
</li>
<li>
<p><code>AI for beginners' lesson on Neural Networks</code>: this will be the data we ground our LLM on</p>
</li>
<li>
<p><code>Azure AI Search</code> and <code>Azure Cosmos DB:</code> vector database to store our data and create a search index</p>
</li>
</ul>
<p>Users will be able to create practice quizzes from their notes, revision flash cards and summarize it to concise overviews. To get started, let us look at what is RAG and how works:</p>
<h2 id="retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)</h2>
<p>An LLM powered chatbot processes user prompts to generate responses. It is designed to be interactive and engages with users on a wide array of topics. However, its responses are limited to the context provided and its foundational training data. For instance, GPT-4 knowledge cutoff is September 2021, meaning, it lacks knowledge of events that have occurred after this period. In addition, the data used to train LLMs excludes confidential information such as personal notes or a company's product manual.</p>
<h3 id="how-rags-retrieval-augmented-generation-work">How RAGs (Retrieval Augmented Generation) work</h3>
<p><img alt="drawing showing how RAGs work" src="images/how-rag-works.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Suppose you want to deploy a chatbot that creates quizzes from your notes, you will require a connection to the knowledge base. This is where RAG comes to the rescue. RAGs operate as follows:</p>
<ul>
<li>
<p><strong>Knowledge base:</strong> Before retrieval, these documents need to be ingested and preprocessed, typically breaking down large documents into smaller chunks, transforming them to text embedding and storing them in a database.</p>
</li>
<li>
<p><strong>User Query:</strong> the user asks a question</p>
</li>
<li>
<p><strong>Retrieval:</strong> When a user asks a question, the embedding model retrieves relevant information from our knowledge base to provide more context that will be incorporated into the prompt.</p>
</li>
<li>
<p><strong>Augmented Generation:</strong> the LLM enhances its response based on the data retrieved. It allows the response generated to be not only based on pre-trained data but also relevant information from the added context. The retrieved data is used to augment the LLM's responses. The LLM then returns an answer to the user's question.</p>
</li>
</ul>
<p><img alt="drawing showing how RAGs architecture" src="images/encoder-decode.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>The architecture for RAGs is implemented using transformers consisting of two parts: an encoder and a decoder. For example, when a user asks a question, the input text 'encoded' into vectors capturing the meaning of words and the vectors are 'decoded' into our document index and generates new text based on the user query. The LLM uses both an encoder-decoder model to generate the output.</p>
<p>Two approaches when implementing RAG according to the proposed paper: <a href="https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst">Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks</a> are:</p>
<ul>
<li>
<p><strong><em>RAG-Sequence</em></strong> using retrieved documents to predict the best possible answer to a user query</p>
</li>
<li>
<p><strong>RAG-Token</strong> using documents to generate the next token, then retrieve them to answer the user's query</p>
</li>
</ul>
<h3 id="why-would-you-use-rags">Why would you use RAGs?</h3>
<ul>
<li>
<p><strong>Information richness:</strong> ensures text responses are up to date and current. It, therefore, enhances performance on domain specific tasks by accessing the internal knowledge base.</p>
</li>
<li>
<p>Reduces fabrication by utilizing <strong>verifiable data</strong> in the knowledge base to provide context to the user queries.</p>
</li>
<li>
<p>It is <strong>cost effective</strong> as they are more economical compared to fine-tuning an LLM</p>
</li>
</ul>
<h2 id="creating-a-knowledge-base">Creating a knowledge base</h2>
<p>Our application is based on our personal data i.e., the Neural Network lesson on AI For Beginners curriculum.</p>
<h3 id="vector-databases">Vector Databases</h3>
<p>A vector database, unlike traditional databases, is a specialized database designed to store, manage and search embedded vectors. It stores numerical representations of documents. Breaking down data to numerical embeddings makes it easier for our AI system to understand and process the data.</p>
<p>We store our embeddings in vector databases as LLMs have a limit of the number of tokens they accept as input. As you cannot pass the entire embeddings to an LLM, we will need to break them down into chunks and when a user asks a question, the embeddings most like the question will be returned together with the prompt. Chunking also reduces costs on the number of tokens passed through an LLM.</p>
<p>Some popular vector databases include Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant and DeepLake. You can create an Azure Cosmos DB model using Azure CLI with the following command:</p>
<pre><code class="language-bash">az login
az group create -n &lt;resource-group-name&gt; -l &lt;location&gt;
az cosmosdb create -n &lt;cosmos-db-name&gt; -r &lt;resource-group-name&gt;
az cosmosdb list-keys -n &lt;cosmos-db-name&gt; -g &lt;resource-group-name&gt;
</code></pre>
<h3 id="from-text-to-embeddings">From text to embeddings</h3>
<p>Before we store our data, we will need to convert it to vector embeddings before it is stored in the database. If you are working with large documents or long texts, you can chunk them based on queries you expect. Chunking can be done at sentence level, or at a paragraph level. As chunking derives meanings from the words around them, you can add some other context to a chunk, for example, by adding the document title or including some text before or after the chunk. You can chunk the data as follows:</p>
<pre><code class="language-python">def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) &lt; max_length and len(' '.join(current_chunk)) &gt; min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
</code></pre>
<p>Once chunked, we can then embed our text using different embedding models. Some models you can use include: word2vec, ada-002 by OpenAI, Azure Computer Vision and many more. Selecting a model to use will depend on the languages you're using, the type of content encoded (text/images/audio), the size of input it can encode and length of the embedding output.</p>
<p>An example of embedded text using OpenAI's <code>text-embedding-ada-002</code> model is:
<img alt="an embedding of the word cat" src="images/cat.png?WT.mc_id=academic-105485-koreyst" /></p>
<h2 id="retrieval-and-vector-search">Retrieval and Vector Search</h2>
<p>When a user asks a question, the retriever transforms it into a vector using the query encoder, it then searches through our document search index for relevant vectors in the document that are related to the input. Once done, it converts both the input vector and document vectors into text and passes it through the LLM.</p>
<h3 id="retrieval">Retrieval</h3>
<p>Retrieval happens when the system tries to quickly find the documents from the index that satisfy the search criteria. The goal of the retriever is to get documents that will be used to provide context and ground the LLM on your data.</p>
<p>There are several ways to perform search within our database such as:</p>
<ul>
<li>
<p><strong>Keyword search</strong> - used for text searches</p>
</li>
<li>
<p><strong>Semantic search</strong> - uses the semantic meaning of words</p>
</li>
<li>
<p><strong>Vector search</strong> - converts documents from text to vector representations using embedding models. Retrieval will be done by querying the documents whose vector representations are closest to the user question.</p>
</li>
<li>
<p><strong>Hybrid</strong> - a combination of both keyword and vector search.</p>
</li>
</ul>
<p>A challenge with retrieval comes in when there is no similar response to the query in the database, the system will then return the best information they can get, however, you can use tactics like set up the maximum distance for relevance or use hybrid search that combines both keywords and vector search. In this lesson we will use hybrid search, a combination of both vector and keyword search. We will store our data into a dataframe with columns containing the chunks as well as embeddings.</p>
<h3 id="vector-similarity">Vector Similarity</h3>
<p>The retriever will search through the knowledge database for embeddings that are close together, the closest neighbour, as they are texts that are similar. In the scenario a user asks a query, it is first embedded then matched with similar embeddings. The common measurement that is used to find how similar different vectors are is cosine similarity which is based on the angle between two vectors.</p>
<p>We can measure similarity using other alternatives we can use are Euclidean distance which is the straight line between vector endpoints and dot product which measures the sum of the products of corresponding elements of two vectors.</p>
<h3 id="search-index">Search index</h3>
<p>When doing retrieval, we will need to build a search index for our knowledge base before we perform search. An index will store our embeddings and can quickly retrieve the most similar chunks even in a large database. We can create our index locally using:</p>
<pre><code class="language-python">from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
</code></pre>
<h3 id="re-ranking">Re-ranking</h3>
<p>Once you have queried the database, you might need to sort the results from the most relevant. A reranking LLM utilizes Machine Learning to improve the relevance of search results by ordering them from the most relevant. Using Azure AI Search, reranking is done automatically for you using a semantic reranker. An example of how reranking works using nearest neighbours:</p>
<pre><code class="language-python"># Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f&quot;Index {index} not found in DataFrame&quot;)
</code></pre>
<h2 id="bringing-it-all-together">Bringing it all together</h2>
<p>The last step is adding our LLM into the mix to be able to get responses that are grounded on our data. We can implement it as follows:</p>
<pre><code class="language-python">user_input = &quot;what is a perceptron?&quot;

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are an AI assistant that helps with AI questions.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model=&quot;gpt-4&quot;,
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
</code></pre>
<h2 id="evaluating-our-application">Evaluating our application</h2>
<h3 id="evaluation-metrics">Evaluation Metrics</h3>
<ul>
<li>
<p>Quality of responses supplied ensuring it sounds natural, fluent and human-like</p>
</li>
<li>
<p>Groundedness of the data: evaluating whether the response that came from supplied docs</p>
</li>
<li>
<p>Relevance: evaluating the response matches and is related to the question asked</p>
</li>
<li>
<p>Fluency - whether the response makes sense grammatically</p>
</li>
</ul>
<h2 id="use-cases-for-using-rag-retervival-augmented-generation-and-vector-databases">Use Cases for using RAG (Retervival Augmented Generation) and vector databases</h2>
<p>There are many different use cases where function calls can improve your app like:</p>
<ul>
<li>
<p>Question and Answering: grounding your company data to a chat that can be used by employees to ask questions.</p>
</li>
<li>
<p>Recommendation Systems: where you can create a system that matches the most similar values e.g. movies, restaurants and many more.</p>
</li>
<li>
<p>Chatbot services: you can store chat history and personalize the conversation based on the user data.</p>
</li>
<li>
<p>Image search based on vector embeddings, useful when doing image recognition and anomaly detection.</p>
</li>
</ul>
<h2 id="summary">Summary</h2>
<p>We have covered the fundamental areas of RAG from adding our data to the application, the user query and output. To simplify creation of RAG, you can use frameworks such as Semanti Kernel, Langchain or Autogen.</p>
<h2 id="assignment">Assignment</h2>
<p>To continue your learning of Retrieval Augmented Generation (RAG) you can build:</p>
<ul>
<li>
<p>Build a front-end for the application using the framework of your choice</p>
</li>
<li>
<p>Utilize a framework, either LangChain or Semantic Kernel, and recreate your application.</p>
</li>
</ul>
<p>Congratulations for completing the lesson 👏.</p>
<h2 id="learning-does-not-stop-here-continue-the-journey">Learning does not stop here, continue the Journey</h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>