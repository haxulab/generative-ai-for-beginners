
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Fundamentos de Engenharia de Prompt - é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#fundamentos-de-engenharia-de-prompt" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" class="md-header__button md-logo" aria-label="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Fundamentos de Engenharia de Prompt
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" class="md-nav__button md-logo" aria-label="é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼AIè¯¾ç¨‹
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    é¢å‘åˆå­¦è€…çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è¯¾ç¨‹ ( Version 3 )
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../00-course-setup/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    è¯¾ç¨‹ä»‹ç»å’Œå­¦ä¹ ç¯å¢ƒè®¾ç½®
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../01-introduction-to-genai/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸€ç«  : ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å’Œ LLMs ä»‹ç»
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../02-exploring-and-comparing-different-llms/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬äºŒç«  : æ¢ç´¢å’Œæ¯”è¾ƒä¸åŒçš„ LLMs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../03-using-generative-ai-responsibly/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸‰ç«  ï¼š è´Ÿè´£ä»»åœ°ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å››ç« ï¼šæç¤ºå·¥ç¨‹åŸºç¡€
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../05-advanced-prompts/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬äº”ç« ï¼šåˆ›å»ºé«˜çº§çš„æç¤ºå·¥ç¨‹æŠ€å·§
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../06-text-generation-apps/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å…­ç« ï¼šåˆ›å»ºæ–‡æœ¬ç”Ÿæˆåº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../07-building-chat-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¸ƒç« ï¼šåˆ›å»ºèŠå¤©åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../08-building-search-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬å…«ç« ï¼šåˆ›å»ºæœç´¢åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../09-building-image-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬ä¹ç« ï¼šæ„å»ºå›¾åƒç”Ÿæˆåº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../10-building-low-code-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åç« ï¼šåˆ›å»ºä½ä»£ç çš„äººå·¥æ™ºèƒ½åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../11-integrating-with-function-calling/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åä¸€ç« ï¼šä¸ºç”Ÿæˆå¼ AI æ·»åŠ  function calling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../12-designing-ux-for-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç¬¬åäºŒç« ï¼šä¸ºäººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºæ·»åŠ ç”¨æˆ·ä½“éªŒ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../13-securing-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ç”Ÿæˆå¼ AI åˆå­¦è€…æŒ‡å—ï¼šç¬¬ 13 ç«  - ä¿æŠ¤ AI åº”ç”¨
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../14-the-generative-ai-application-lifecycle/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../15-rag-and-vector-databases/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ä¸å‘é‡æ•°æ®åº“
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../16-open-source-models/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../17-ai-agents/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../18-fine-tuning/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../19-slm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Small Language Models for Generative AI for Beginners
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../20-mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building with Mistral Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../21-meta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building With the Meta Family Models
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#metas-de-aprendizado" class="md-nav__link">
    <span class="md-ellipsis">
      Metas de Aprendizado
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sandbox-de-aprendizado" class="md-nav__link">
    <span class="md-ellipsis">
      Sandbox de Aprendizado
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nossa-startup" class="md-nav__link">
    <span class="md-ellipsis">
      Nossa Startup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#o-que-e-engenharia-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      O que Ã© Engenharia de Prompt?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="O que Ã© Engenharia de Prompt?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tokenizacao" class="md-nav__link">
    <span class="md-ellipsis">
      TokenizaÃ§Ã£o
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conceito-modelos-fundamentais" class="md-nav__link">
    <span class="md-ellipsis">
      Conceito: Modelos Fundamentais
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conceito-llms-instruidos" class="md-nav__link">
    <span class="md-ellipsis">
      Conceito: LLMs InstruÃ­dos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#por-que-precisamos-de-engenharia-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Por que precisamos de Engenharia de Prompt?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Por que precisamos de Engenharia de Prompt?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exemplo-de-alucinacoes" class="md-nav__link">
    <span class="md-ellipsis">
      Exemplo de AlucinaÃ§Ãµes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#estudo-de-caso-github-copilot" class="md-nav__link">
    <span class="md-ellipsis">
      Estudo de Caso: GitHub Copilot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#construcao-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      ConstruÃ§Ã£o de Prompt
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ConstruÃ§Ã£o de Prompt">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompt-basico" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt BÃ¡sico
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prompt-complexo" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Complexo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prompt-de-instrucao" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt de InstruÃ§Ã£o
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conteudo-primario" class="md-nav__link">
    <span class="md-ellipsis">
      ConteÃºdo PrimÃ¡rio
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ConteÃºdo PrimÃ¡rio">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#usando-exemplos" class="md-nav__link">
    <span class="md-ellipsis">
      Usando Exemplos
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dicas-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Dicas de Prompt
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modelos-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Modelos de Prompt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conteudo-de-suporte" class="md-nav__link">
    <span class="md-ellipsis">
      ConteÃºdo de Suporte
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#melhores-praticas-para-prompts" class="md-nav__link">
    <span class="md-ellipsis">
      Melhores PrÃ¡ticas para Prompts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Melhores PrÃ¡ticas para Prompts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mentalidade-de-engenharia-de-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Mentalidade de Engenharia de Prompt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#melhores-praticas" class="md-nav__link">
    <span class="md-ellipsis">
      Melhores PrÃ¡ticas
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tarefa" class="md-nav__link">
    <span class="md-ellipsis">
      Tarefa
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tarefa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#para-comecar-faca-um-fork-do-repositorio-depois" class="md-nav__link">
    <span class="md-ellipsis">
      Para comeÃ§ar, faÃ§a um fork do repositÃ³rio, depois
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#em-seguida-configure-suas-variaveis-de-ambiente" class="md-nav__link">
    <span class="md-ellipsis">
      Em seguida, configure suas variÃ¡veis de ambiente
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#em-seguida-abra-o-jupyter-notebook" class="md-nav__link">
    <span class="md-ellipsis">
      Em seguida, abra o Jupyter Notebook
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#verificacao-de-conhecimento" class="md-nav__link">
    <span class="md-ellipsis">
      VerificaÃ§Ã£o de Conhecimento
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#desafio" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸš€ Desafio
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#otimo-trabalho-continue-sua-aprendizagem" class="md-nav__link">
    <span class="md-ellipsis">
      Ã“timo Trabalho! Continue Sua Aprendizagem
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="fundamentos-de-engenharia-de-prompt">Fundamentos de Engenharia de Prompt</h1>
<p><a href="https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst"><img alt="Prompt Engineering Fundamentals" src="../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<p>A forma como vocÃª escreve seu prompt para o LLM importa. Um prompt cuidadosamente elaborado pode alcanÃ§ar um resultado melhor do que um que nÃ£o Ã©. Mas o que sÃ£o esses conceitos, prompt, Engenharia de Prompt e como posso melhorar o que envio para o LLM? Perguntas como essas sÃ£o o que este capÃ­tulo e o prÃ³ximo estÃ£o procurando responder.</p>
<p><em>A IA Generativa</em> Ã© capaz de criar novo conteÃºdo (por exemplo, texto, imagens, Ã¡udio, cÃ³digo etc.) em resposta a solicitaÃ§Ãµes do usuÃ¡rio. Isso Ã© alcanÃ§ado usando <em>Modelos de Linguagem Grandes</em> (LLMs) como a sÃ©rie GPT ("Generative Pre-trained Transformer") da OpenAI, que sÃ£o treinados para usar linguagem natural e cÃ³digo.</p>
<p>Os usuÃ¡rios agora podem interagir com esses modelos usando paradigmas familiares como chat, sem precisar de nenhuma experiÃªncia tÃ©cnica ou treinamento. Os modelos sÃ£o <em>baseados em prompt</em> - os usuÃ¡rios enviam uma entrada de texto (prompt) e recebem a resposta da IA (completaÃ§Ã£o). Eles podem entÃ£o "conversar com a IA" de forma iterativa, em conversas de vÃ¡rias rodadas, refinando seu prompt atÃ© que a resposta atenda Ã s suas expectativas.</p>
<p>"Prompts" agora se tornam a principal <em>interface de programaÃ§Ã£o</em> para aplicativos de IA generativa, indicando aos modelos o que fazer e influenciando a qualidade das respostas retornadas. "Engenharia de Prompt" Ã© um campo de estudo em rÃ¡pido crescimento que se concentra no <em>design e otimizaÃ§Ã£o</em> de prompts para fornecer respostas consistentes e de qualidade em escala.</p>
<h2 id="metas-de-aprendizado">Metas de Aprendizado</h2>
<p>Nesta liÃ§Ã£o, aprenderemos o que Ã© Engenharia de Prompt, por que isso Ã© importante e como podemos criar prompts mais eficazes para um modelo e objetivo de aplicativo especÃ­ficos. Compreenderemos os conceitos centrais e as melhores prÃ¡ticas para a Engenharia de Prompt - e conheceremos um ambiente interativo de Jupyter Notebooks "sandbox" onde podemos ver esses conceitos aplicados a exemplos reais.</p>
<p>Ao final desta liÃ§Ã£o, seremos capazes de:</p>
<ol>
<li>Explicar o que Ã© Engenharia de Prompt e por que isso importa.</li>
<li>Descrever os componentes de um prompt e como eles sÃ£o usados.</li>
<li>Aprender melhores prÃ¡ticas e tÃ©cnicas para a Engenharia de Prompt.</li>
<li>Aplicar tÃ©cnicas aprendidas a exemplos reais, usando um endpoint da OpenAI.</li>
</ol>
<h2 id="sandbox-de-aprendizado">Sandbox de Aprendizado</h2>
<p>A Engenharia de Prompt Ã© atualmente mais uma arte do que uma ciÃªncia. A melhor maneira de aprimorar nossa intuiÃ§Ã£o Ã© <em>praticar mais</em> e adotar uma abordagem de tentativa e erro que combine experiÃªncia no domÃ­nio de aplicaÃ§Ã£o com tÃ©cnicas recomendadas e otimizaÃ§Ãµes especÃ­ficas do modelo.</p>
<p>O Jupyter Notebook que acompanha esta liÃ§Ã£o, fornece um ambiente <em>sandbox</em> onde vocÃª pode experimentar o que aprende - Ã  medida que avanÃ§a ou como parte do desafio de cÃ³digo no final. Para executar os exercÃ­cios, vocÃª precisarÃ¡ de:</p>
<ol>
<li>
<p>Uma chave de API da OpenAI - o endpoint de serviÃ§o para um LLM implantado.</p>
</li>
<li>
<p>Um tempo de execuÃ§Ã£o Python - no qual o Notebook pode ser executado.</p>
</li>
</ol>
<p>NÃ³s instrumentamos este repositÃ³rio com um <em>contÃªiner de desenvolvimento</em> (<em>dev container</em>) que vem com um tempo de execuÃ§Ã£o Python 3. Abra simplesmente o repositÃ³rio no GitHub Codespaces ou no seu Docker Desktop localmente para ativar o tempo de execuÃ§Ã£o automaticamente. Em seguida, abra o notebook e selecione o kernel Python 3.x para preparar o Notebook para execuÃ§Ã£o.</p>
<p>O notebook padrÃ£o estÃ¡ configurado para uso com uma chave de API da OpenAI. Basta copiar o arquivo <code>.env.copy</code> na raiz da pasta para <code>.env</code> e atualizar a linha <code>OPENAI_API_KEY=</code> com sua chave de API - e vocÃª estarÃ¡ pronto.</p>
<p>O notebook vem com exercÃ­cios <em>iniciais</em>, mas vocÃª Ã© incentivado a adicionar suas prÃ³prias seÃ§Ãµes de <em>Markdown</em> (descriÃ§Ã£o) e <em>CÃ³digo</em> (solicitaÃ§Ãµes de prompt) para experimentar mais exemplos ou ideias - e construir sua intuiÃ§Ã£o para o design de prompt.</p>
<h2 id="nossa-startup">Nossa Startup</h2>
<p>Agora, vamos falar sobre como <em>esse tÃ³pico</em> se relaciona com a missÃ£o de nossa startup de <a href="https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst">trazer inovaÃ§Ã£o de IA para a educaÃ§Ã£o</a>. Queremos criar aplicaÃ§Ãµes de aprendizado personalizado impulsionados por IA. EntÃ£o, vamos pensar em como diferentes usuÃ¡rios da nossa aplicaÃ§Ã£o podem "projetar" prompts:</p>
<ul>
<li><strong>Administradores</strong> podem pedir Ã  IA para <em>analisar dados do currÃ­culo para identificar lacunas na cobertura</em>. A IA pode resumir os resultados ou visualizÃ¡-los com cÃ³digo.</li>
<li><strong>Educadores</strong> podem pedir Ã  IA para <em>gerar um plano de aula para um pÃºblico-alvo e tÃ³pico</em>. A IA pode criar o plano personalizado em um formato especificado.</li>
<li><strong>Alunos</strong> podem pedir Ã  IA para <em>ajudÃ¡-los em uma disciplina difÃ­cil</em>. A IA pode orientar os alunos com liÃ§Ãµes, dicas e exemplos adaptados ao seu nÃ­vel.</li>
</ul>
<p>Isso Ã© apenas a ponta do iceberg. Confira <a href="https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst">Prompts For Education</a> - uma biblioteca de prompts de cÃ³digo aberto curada por especialistas em educaÃ§Ã£o - para ter uma visÃ£o mais ampla das possibilidades! <em>Experimente executar alguns desses prompts na sandbox ou usando o OpenAI Playground para ver o que acontece!</em></p>
<!--
MODELO DE LIÃ‡ÃƒO:
Esta unidade deve abordar o conceito principal #1.
Reforce o conceito com exemplos e referÃªncias.

CONCEITO #1:
Engenharia de Prompt.
Defina-o e explique por que Ã© necessÃ¡rio.
-->

<h2 id="o-que-e-engenharia-de-prompt">O que Ã© Engenharia de Prompt?</h2>
<p>ComeÃ§amos esta liÃ§Ã£o definindo <strong>Engenharia de Prompt</strong> como o processo de <em>projetar e otimizar</em> entradas de texto (prompts) para fornecer respostas consistentes e de qualidade (completions) para um objetivo de aplicativo e modelo especÃ­ficos. Podemos pensar nisso como um processo de 2 etapas:</p>
<ul>
<li><em>projetar</em> o prompt inicial para um modelo e objetivo especÃ­ficos</li>
<li><em>refinar</em> iterativamente o prompt para melhorar a qualidade da resposta</li>
</ul>
<p>Isso Ã© necessariamente um processo de tentativa e erro que requer intuiÃ§Ã£o do usuÃ¡rio e esforÃ§o para obter resultados Ã³timos. EntÃ£o, por que Ã© importante? Para responder a essa pergunta, primeiro precisamos entender trÃªs conceitos:</p>
<ul>
<li><em>TokenizaÃ§Ã£o</em> = como o modelo "enxerga" o prompt</li>
<li><em>Base LLMs</em> = como o modelo fundamental "processa" um prompt</li>
<li><em>Instruction-Tuned LLMs</em> = como o modelo agora pode ver "tarefas"</li>
</ul>
<h3 id="tokenizacao">TokenizaÃ§Ã£o</h3>
<p>Um LLM vÃª prompts como uma <em>sequÃªncia de tokens</em> onde diferentes modelos (ou versÃµes de um modelo) podem tokenizar o mesmo prompt de maneiras diferentes. Como os LLMs sÃ£o treinados em tokens (nÃ£o em texto bruto), a forma como os prompts sÃ£o tokenizados tem um impacto direto na qualidade da resposta gerada.</p>
<p>Para ter uma intuiÃ§Ã£o de como a tokenizaÃ§Ã£o funciona, experimente ferramentas como o <a href="https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst">OpenAI Tokenizer</a> mostrado abaixo. Copie seu prompt e veja como ele Ã© convertido em tokens, prestando atenÃ§Ã£o em como caracteres de espaÃ§o em branco e pontuaÃ§Ãµes sÃ£o tratados. Note que este exemplo mostra um LLM mais antigo (GPT-3) - entÃ£o, tentar isso com um modelo mais recente pode produzir um resultado diferente.</p>
<p><img alt="Tokenization" src="../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst" /></p>
<h3 id="conceito-modelos-fundamentais">Conceito: Modelos Fundamentais</h3>
<p>Uma vez que um prompt Ã© tokenizado, a funÃ§Ã£o principal do <a href="https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst">"Base LLM"</a> (ou modelo fundamental) Ã© prever o token nessa sequÃªncia. Como os LLMs sÃ£o treinados em conjuntos massivos de dados de texto, eles tÃªm uma boa compreensÃ£o das relaÃ§Ãµes estatÃ­sticas entre tokens e podem fazer essa previsÃ£o com alguma confianÃ§a.</p>
<blockquote>
<p>ObservaÃ§Ã£o: eles nÃ£o compreendem o <em>significado</em> das palavras no prompt ou token; eles apenas veem um padrÃ£o que podem "completar" com sua prÃ³xima previsÃ£o. Eles podem continuar prevendo a sequÃªncia atÃ© serem interrompidos pela intervenÃ§Ã£o do usuÃ¡rio ou alguma condiÃ§Ã£o preestabelecida.</p>
</blockquote>
<p>Desejam ver como a conclusÃ£o baseada em prompts funciona? Insira o prompt acima no <a href="https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst"><em>Chat Playground</em></a> do Azure OpenAI Studio com as configuraÃ§Ãµes padrÃ£o. O sistema estÃ¡ configurado para tratar prompts como solicitaÃ§Ãµes de informaÃ§Ã£o - entÃ£o, vocÃª deve ver uma conclusÃ£o que atende a esse contexto.</p>
<p>Mas e se o usuÃ¡rio quiser ver algo especÃ­fico que atenda a alguns critÃ©rios ou objetivos de tarefa? Ã‰ aqui que os LLMs <em>instruÃ­dos</em> entram em cena.</p>
<p><img alt="Base LLM Chat Completion" src="../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst" /></p>
<h3 id="conceito-llms-instruidos">Conceito: LLMs InstruÃ­dos</h3>
<p>Um <a href="https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst">LLM InstruÃ­do</a> comeÃ§a com o modelo fundamental e o ajusta com exemplos ou pares de entrada/saÃ­da (por exemplo, "mensagens" de vÃ¡rias rodadas) que podem conter instruÃ§Ãµes claras - e a resposta da IA tenta seguir essa instruÃ§Ã£o.</p>
<p>Isso usa tÃ©cnicas como Aprendizado por ReforÃ§o com Feedback Humano (ARFH) que podem treinar o modelo a <em>seguir instruÃ§Ãµes</em> e <em>aprender com feedback</em> para que produza respostas mais adequadas a aplicaÃ§Ãµes prÃ¡ticas e mais relevantes para objetivos do usuÃ¡rio.</p>
<p>Vamos experimentar - revisite o prompt acima, mas agora altere a <em>mensagem do sistema</em> para fornecer a seguinte instruÃ§Ã£o como contexto:</p>
<blockquote>
<p><em>Summarize content you are provided with for a second-grade student. Keep the result to one paragraph with 3-5 bullet points.</em></p>
</blockquote>
<p>Veja como o resultado agora estÃ¡ ajustado para refletir o objetivo desejado e o formato? Um educador pode agora usar diretamente essa resposta em seus slides para aquela aula.</p>
<p><img alt="Instruction Tuned LLM Chat Completion" src="../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst" /></p>
<h2 id="por-que-precisamos-de-engenharia-de-prompt">Por que precisamos de Engenharia de Prompt?</h2>
<p>Agora que sabemos como os prompts sÃ£o processados pelos LLMs, vamos falar sobre <em>por que</em> precisamos de Engenharia de Prompt. A resposta estÃ¡ no fato de que os LLMs atuais apresentam uma sÃ©rie de desafios que tornam as <em>completions confiÃ¡veis e consistentes</em> mais difÃ­ceis de alcanÃ§ar sem esforÃ§o na criaÃ§Ã£o e otimizaÃ§Ã£o do prompt. Por exemplo:</p>
<ol>
<li>
<p><strong>As respostas do modelo sÃ£o estocÃ¡sticas.</strong> O <em>mesmo prompt</em> provavelmente produzirÃ¡ respostas diferentes com modelos ou versÃµes diferentes do modelo. E pode atÃ© mesmo produzir resultados diferentes com o <em>mesmo modelo</em> em momentos diferentes. <em>TÃ©cnicas de Wngenharia de Prompt podem nos ajudar a minimizar essas variaÃ§Ãµes fornecendo melhores diretrizes</em>.</p>
</li>
<li>
<p><strong>Os modelos podem criar respostas imaginÃ¡rias.</strong> Os modelos sÃ£o prÃ©-treinados com conjuntos de dados <em>grandes, mas finitos</em>, o que significa que eles nÃ£o tÃªm conhecimento sobre conceitos fora desse escopo de treinamento. Como resultado, podem produzir completions imprecisas, imaginÃ¡rias ou diretamente contraditÃ³rias aos fatos conhecidos. <em>TÃ©cnicas de Engenharia de Prompt ajudam os usuÃ¡rios a identificar e mitigar alucinaÃ§Ãµes, por exemplo, pedindo Ã  IA por citaÃ§Ãµes ou raciocÃ­nio</em>.</p>
</li>
<li>
<p><strong>As capacidades dos modelos variarÃ£o.</strong> Modelos ou geraÃ§Ãµes de modelos mais recentes terÃ£o capacidades mais ricas, mas tambÃ©m trarÃ£o peculiaridades e compensaÃ§Ãµes Ãºnicas em termos de custo e complexidade. <em>A Engenharia de Prompt pode nos ajudar a desenvolver melhores prÃ¡ticas e fluxos de trabalho que abstraem diferenÃ§as e se adaptam aos requisitos especÃ­ficos do modelo de maneira escalÃ¡vel e contÃ­nua</em>.</p>
</li>
</ol>
<p>Vamos ver isso em aÃ§Ã£o no OpenAI ou Azure OpenAI Playground:</p>
<ul>
<li>Use o mesmo prompt com diferentes implantaÃ§Ãµes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) - vocÃª viu as variaÃ§Ãµes?</li>
<li>Use o mesmo prompt repetidamente com a <em>mesma</em> implantaÃ§Ã£o de LLM (por exemplo, Azure OpenAI Playground) - como essas variaÃ§Ãµes diferiram?</li>
</ul>
<h3 id="exemplo-de-alucinacoes">Exemplo de AlucinaÃ§Ãµes</h3>
<p>Quer ter uma ideia de como as alucinaÃ§Ãµes funcionam? Pense em um prompt que instrua a IA a gerar conteÃºdo para um tÃ³pico inexistente (para garantir que nÃ£o seja encontrado no conjunto de dados de treinamento). Por exemplo - eu tentei este prompt:</p>
<blockquote>
<p><strong>Prompt:</strong> generate a lesson plan on the Martian War of 2076.</p>
</blockquote>
<p>Uma busca na web mostrou que havia relatos fictÃ­cios (por exemplo, sÃ©ries de televisÃ£o ou livros) sobre guerras marcianas - mas nenhuma em 2076. O bom senso tambÃ©m nos diz que 2076 estÃ¡ <em>no futuro</em> e, portanto, nÃ£o pode ser associado a um evento real.</p>
<p>EntÃ£o, o que acontece quando executamos este prompt com diferentes provedores de LLM?</p>
<blockquote>
<p><strong>Resposta 1</strong>: OpenAI Playground (GPT-35)</p>
</blockquote>
<p><img alt="Resposta 1" src="../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst" /></p>
<blockquote>
<p><strong>Resposta 2</strong>: Azure OpenAI Playground (GPT-35)</p>
</blockquote>
<p><img alt="Response 2" src="../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst" /></p>
<blockquote>
<p><strong>Resposta 3</strong>: : Hugging Face Chat Playground (LLama-2)</p>
</blockquote>
<p><img alt="Response 3" src="../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Como esperado, cada modelo (ou versÃ£o do modelo) produz respostas ligeiramente diferentes devido ao comportamento estocÃ¡stico e variaÃ§Ãµes nas capacidades do modelo. Por exemplo, um modelo tem como alvo uma audiÃªncia do 8Âº ano, enquanto o outro assume um estudante do ensino mÃ©dio. Mas os trÃªs modelos geraram respostas que poderiam convencer um usuÃ¡rio desinformado de que o evento era real.</p>
<p>TÃ©cnicas de engenharia de prompt como <em>metaprompting</em> e <em>configuraÃ§Ã£o de temperatura</em> podem reduzir as alucinaÃ§Ãµes do modelo em certa medida. Novas <em>arquiteturas</em> de engenharia de prompt tambÃ©m incorporam novas ferramentas e tÃ©cnicas de maneira contÃ­nua no fluxo do prompt, para mitigar ou reduzir alguns desses efeitos.</p>
<h2 id="estudo-de-caso-github-copilot">Estudo de Caso: GitHub Copilot</h2>
<p>Vamos concluir esta seÃ§Ã£o entendendo como a engenharia de prompt Ã© utilizada em soluÃ§Ãµes do mundo real ao analisar um Estudo de Caso: <a href="https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst">GitHub Copilot</a>.</p>
<p>O GitHub Copilot Ã© seu "Programador de Par IA" - ele converte prompts de texto em conclusÃµes de cÃ³digo e estÃ¡ integrado ao seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experiÃªncia do usuÃ¡rio sem interrupÃ§Ãµes. Como documentado na sÃ©rie de blogs abaixo, a versÃ£o mais antiga era baseada no modelo OpenAI Codex - com os engenheiros percebendo rapidamente a necessidade de ajustar o modelo e desenvolver tÃ©cnicas melhores de engenharia de prompt para melhorar a qualidade do cÃ³digo. Em julho, eles <a href="https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst">apresentaram um modelo de IA aprimorado que vai alÃ©m do Codex</a> para sugestÃµes ainda mais rÃ¡pidas.</p>
<p>Leia as postagens na ordem para seguir a jornada de aprendizado deles.</p>
<ul>
<li><strong>Maio de 2023</strong> | <a href="https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst">GitHub Copilot estÃ¡ Melhorando na CompreensÃ£o do Seu CÃ³digo</a></li>
<li><strong>Maio de 2023</strong> | <a href="https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst">Dentro do GitHub: Trabalhando com os LLMs por trÃ¡s do GitHub Copilot</a>.</li>
<li><strong>Junho de 2023</strong> | <a href="https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst">Como Escrever Melhores Prompts para o GitHub Copilot</a>.</li>
<li><strong>Julho de 2023</strong> | <a href="https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst">.. GitHub Copilot vai alÃ©m do Codex com modelo de IA aprimorado</a></li>
<li><strong>Julho de 2023</strong> | <a href="https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst">Guia do Desenvolvedor para Engenharia de Prompt e LLMs</a></li>
<li><strong>Setembro de 2023</strong> | <a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst">Como construir um aplicativo empresarial LLM: LiÃ§Ãµes do GitHub Copilot</a></li>
</ul>
<p>VocÃª tambÃ©m pode navegar pelo <a href="https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst">blog de Engenharia deles</a> para mais postagens como <a href="https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst">esta</a> que mostra como esses modelos e tÃ©cnicas sÃ£o <em>aplicados</em> para impulsionar aplicaÃ§Ãµes do mundo real.</p>
<hr />
<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

<h2 id="construcao-de-prompt">ConstruÃ§Ã£o de Prompt</h2>
<p>Vimos por que a Engenharia de Prompt Ã© importante - agora vamos entender como os prompts sÃ£o <em>construÃ­dos</em> para que possamos avaliar diferentes tÃ©cnicas para um design de prompt mais eficaz.</p>
<h3 id="prompt-basico">Prompt BÃ¡sico</h3>
<p>Vamos comeÃ§ar com o prompt bÃ¡sico: uma entrada de texto enviada ao modelo sem nenhum outro contexto. Aqui estÃ¡ um exemplo - quando enviamos as primeiras palavras do hino nacional dos EUA para a <a href="https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst">API de Completions da OpenAI</a>, ela instantaneamente <em>completa</em> a resposta com as prÃ³ximas linhas, ilustrando o comportamento bÃ¡sico de previsÃ£o.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Prompt (Input)</th>
<th style="text-align: left;">Completion (Output)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Oh say can you see</td>
<td style="text-align: left;">It sounds like you're starting the lyrics to "The Star-Spangled Banner," the national anthem of the United States. The full lyrics are ...</td>
</tr>
</tbody>
</table>
<h3 id="prompt-complexo">Prompt Complexo</h3>
<p>Agora, vamos adicionar contexto e instruÃ§Ãµes a esse prompt bÃ¡sico. A <a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst">API de Completions de Chat</a> nos permite construir um prompt complexo como uma coleÃ§Ã£o de <em>mensagens</em> com:</p>
<ul>
<li>Pares de entrada/saÃ­da refletindo a entrada do <em>usuÃ¡rio</em> e a resposta do <em>assistente</em>.</li>
<li>Mensagem do sistema definindo o contexto para o comportamento ou personalidade do assistente.</li>
</ul>
<p>A solicitaÃ§Ã£o agora estÃ¡ na forma abaixo, onde a <em>tokenizaÃ§Ã£o</em> captura efetivamente informaÃ§Ãµes relevantes do contexto e da conversa. Agora, alterar o contexto do sistema pode ter um impacto significativo na qualidade dos completamentos, assim como as entradas do usuÃ¡rio fornecidas.</p>
<pre><code class="language-python">response = openai.chat.completions.create(
    model=&quot;gpt-3.5-turbo&quot;,
    messages=[
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;VocÃª Ã© um assistente prestativo.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Quem ganhou a sÃ©rie mundial em 2020?&quot;},
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;O Los Angeles Dodgers venceu a SÃ©rie Mundial em 2020.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Onde foi jogado?&quot;}
    ]
)
</code></pre>
<h3 id="prompt-de-instrucao">Prompt de InstruÃ§Ã£o</h3>
<p>Nos exemplos acima, o prompt do usuÃ¡rio era uma simples consulta de texto que pode ser interpretada como uma solicitaÃ§Ã£o de informaÃ§Ãµes. Com prompts de <em>instruÃ§Ã£o</em>, podemos usar esse texto para especificar uma tarefa de maneira mais detalhada, fornecendo orientaÃ§Ãµes melhores para a IA. Aqui estÃ¡ um exemplo:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Prompt (Input)</th>
<th style="text-align: left;">Completion (Output)</th>
<th style="text-align: left;">Instruction Type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Write a description of the Civil War</td>
<td style="text-align: left;"><em>returned a simple paragraph</em></td>
<td style="text-align: left;">Simple</td>
</tr>
<tr>
<td style="text-align: left;">Write a description of the Civil War. Provide key dates and events and describe their significance</td>
<td style="text-align: left;"><em>returned a paragraph followed by a list of key event dates with descriptions</em></td>
<td style="text-align: left;">Complex</td>
</tr>
<tr>
<td style="text-align: left;">Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file</td>
<td style="text-align: left;"><em>returns more extensive details in a text box, formatted as JSON that you can copy-paste to a file and validate as needed</em></td>
<td style="text-align: left;">Complex. Formatted.</td>
</tr>
</tbody>
</table>
<h2 id="conteudo-primario">ConteÃºdo PrimÃ¡rio</h2>
<p>Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse qual parte de seu conjunto de dados prÃ©-treinado era relevante. Com o padrÃ£o de design de <em>conteÃºdo primÃ¡rio</em>, o texto de entrada Ã© dividido em duas partes:</p>
<ul>
<li>uma instruÃ§Ã£o (aÃ§Ã£o)</li>
<li>conteÃºdo relevante (que influencia a aÃ§Ã£o)</li>
</ul>
<p>Aqui estÃ¡ um exemplo em que a instruÃ§Ã£o Ã©: "resuma isso em 2 frases".</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Prompt (Input)</th>
<th style="text-align: left;">Completion (Output)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus. <br/> <strong>Summarize this in 2 short sentences</strong></td>
<td style="text-align: left;">Jupiter, the fifth planet from the Sun, is the largest in the Solar System and is known for being one of the brightest objects in the night sky. Named after the Roman god Jupiter, it's a gas giant whose mass is two-and-a-half times that of all other planets in the Solar System combined.</td>
</tr>
</tbody>
</table>
<p>O segmento de conteÃºdo primÃ¡rio pode ser usado de vÃ¡rias maneiras para impulsionar instruÃ§Ãµes mais eficazes:</p>
<ul>
<li><strong>Exemplos</strong> - em vez de dizer explicitamente ao modelo o que fazer com uma instruÃ§Ã£o explÃ­cita, dÃª a ele exemplos do que fazer e deixe-o inferir o padrÃ£o.</li>
<li><strong>Dicas</strong> - siga a instruÃ§Ã£o com uma "dica" que prepara o completamento, orientando o modelo para respostas mais relevantes.</li>
<li><strong>Modelos</strong> - sÃ£o 'receitas' repetÃ­veis de prompts com espaÃ§os reservados (variÃ¡veis) que podem ser personalizados com dados para casos de uso especÃ­ficos.</li>
</ul>
<p>Vamos explorar esses conceitos na prÃ¡tica.</p>
<h3 id="usando-exemplos">Usando Exemplos</h3>
<p>Esta Ã© uma abordagem em que vocÃª usa o conteÃºdo primÃ¡rio para "alimentar o modelo" com alguns exemplos da saÃ­da desejada para uma determinada instruÃ§Ã£o e permite que ele infera o padrÃ£o para a saÃ­da desejada. Com base no nÃºmero de exemplos fornecidos, podemos ter prompting de <code>zero-shot</code>, <code>one-shot</code>, <code>few-shot</code>, etc.</p>
<p>O prompt agora consiste em trÃªs componentes:</p>
<ul>
<li>Uma descriÃ§Ã£o da tarefa</li>
<li>Alguns exemplos da saÃ­da desejada</li>
<li>O inÃ­cio de um novo exemplo (que se torna uma descriÃ§Ã£o implÃ­cita da tarefa)</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">Learning Type</th>
<th style="text-align: left;">Prompt (Input)</th>
<th style="text-align: left;">Completion (Output)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Zero-shot</td>
<td style="text-align: left;">"The Sun is Shining". Translate to Spanish</td>
<td style="text-align: left;">"El Sol estÃ¡ brillando".</td>
</tr>
<tr>
<td style="text-align: left;">One-shot</td>
<td style="text-align: left;">"The Sun is Shining" =&gt; ""El Sol estÃ¡ brillando". <br> "It's a Cold and Windy Day" =&gt;</td>
<td style="text-align: left;">"Es un dÃ­a frÃ­o y ventoso".</td>
</tr>
<tr>
<td style="text-align: left;">Few-shot</td>
<td style="text-align: left;">The player ran the bases =&gt; Baseball <br/> The player hit an ace =&gt; Tennis <br/> The player hit a six =&gt; Cricket <br/> The player made a slam-dunk =&gt;</td>
<td style="text-align: left;">Basketball</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Observe como tivemos que fornecer instruÃ§Ãµes explÃ­citas ("Traduza para o espanhol") no prompting de <code>zero-shot</code>, mas isso Ã© inferido no exemplo de <code>one-shot</code>. O exemplo <code>few-shot</code> mostra como adicionar mais exemplos permite que os modelos faÃ§am inferÃªncias mais precisas sem instruÃ§Ãµes adicionais.</p>
<h3 id="dicas-de-prompt">Dicas de Prompt</h3>
<p>Outra tÃ©cnica para usar conteÃºdo primÃ¡rio Ã© fornecer <em>dicas</em> em vez de exemplos. Neste caso, estamos dando ao modelo um empurrÃ£o na direÃ§Ã£o certa ao <em>iniciÃ¡-lo</em> com um trecho que reflete o formato da resposta desejada. O modelo entÃ£o "pega a dica" para continuar nessa linha.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Number of Cues</th>
<th style="text-align: left;">Prompt (Input)</th>
<th style="text-align: left;">Completion (Output)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0</td>
<td style="text-align: left;">Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/><strong>Summarize This</strong></td>
<td style="text-align: left;">Jupiter is the largest planet in our Solar System and the fifth one from the Sun. It is a gas giant with a mass 1/1000th of the Sun's, but it is heavier than all the other planets combined. Ancient civilizations have known about Jupiter for a long time, and it is easily visible in the night sky..</td>
</tr>
<tr>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/><strong>Summarize This</strong> <br/> What we learned is that Jupiter</td>
<td style="text-align: left;">is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets combined. It is easily visible to the naked eye and has been known since ancient times.</td>
</tr>
<tr>
<td style="text-align: left;">2</td>
<td style="text-align: left;">Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/><strong>Summarize This</strong> <br/> Top 3 Facts We Learned:</td>
<td style="text-align: left;">1. Jupiter is the fifth planet from the Sun and the largest in the Solar System. <br/> 2. It is a gas giant with a mass one-thousandth that of the Sun...<br/> 3. Jupiter has been visible to the naked eye since ancient times ...</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Observe como tivemos que fornecer uma instruÃ§Ã£o explÃ­cita ("Resuma Isso") no exemplo de zero dicas, mas isso Ã© inferido no exemplo de uma dica. O exemplo de duas dicas mostra como adicionar mais dicas permite que os modelos faÃ§am inferÃªncias mais precisas sem instruÃ§Ãµes adicionais.</p>
<h3 id="modelos-de-prompt">Modelos de Prompt</h3>
<p>Um modelo de prompt Ã© uma <em>receita prÃ©-definida para um prompt</em> que pode ser armazenada e reutilizada conforme necessÃ¡rio, para proporcionar experiÃªncias do usuÃ¡rio mais consistentes em escala. Em sua forma mais simples, Ã© apenas uma coleÃ§Ã£o de exemplos de prompt como <a href="https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst">este da OpenAI</a> que fornece tanto os componentes interativos do prompt (mensagens do usuÃ¡rio e do sistema) quanto o formato de solicitaÃ§Ã£o impulsionado por API - para suportar a reutilizaÃ§Ã£o.</p>
<p>Em sua forma mais complexa, como <a href="https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst">este exemplo em LangChain</a>, contÃ©m <em>placeholders</em> que podem ser substituÃ­dos por dados de diversas fontes (entrada do usuÃ¡rio, contexto do sistema, fontes de dados externas etc.) para gerar um prompt dinamicamente. Isso nos permite criar uma biblioteca de prompts reutilizÃ¡veis que podem ser usados para impulsionar experiÃªncias do usuÃ¡rio consistentes <strong>programaticamente</strong> em escala.</p>
<p>Finalmente, o real valor dos modelos estÃ¡ na capacidade de criar e publicar <em>bibliotecas de prompts</em> para domÃ­nios de aplicaÃ§Ã£o verticais - onde o modelo de prompt Ã© agora <em>otimizado</em> para refletir o contexto ou exemplos especÃ­ficos do domÃ­nio da aplicaÃ§Ã£o que tornam as respostas mais relevantes e precisas para o pÃºblico-alvo.</p>
<p>A <a href="https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst">Prompts For Edu</a> Ã© um Ã³timo exemplo dessa abordagem, criando uma biblioteca de prompts para o domÃ­nio da educaÃ§Ã£o com Ãªnfase em objetivos-chave como planejamento de aulas, design de currÃ­culo, tutoria de estudantes etc.</p>
<h2 id="conteudo-de-suporte">ConteÃºdo de Suporte</h2>
<p>Se pensarmos na criaÃ§Ã£o do prompt como tendo uma instruÃ§Ã£o (tarefa) e um alvo (conteÃºdo principal), entÃ£o o <em>conteÃºdo secundÃ¡rio</em> Ã© como um contexto adicional que fornecemos para <strong>influenciar a saÃ­da de alguma forma</strong>. Pode ser parÃ¢metros de ajuste, instruÃ§Ãµes de formataÃ§Ã£o, taxonomias de tÃ³picos etc. que podem ajudar o modelo a <em>adequar</em> sua resposta para atender aos objetivos ou expectativas desejados do usuÃ¡rio.</p>
<p>Por exemplo: Dado um catÃ¡logo de cursos com metadados extensivos (nome, descriÃ§Ã£o, nÃ­vel, tags de metadados, instrutor etc.) de todos os cursos disponÃ­veis no currÃ­culo:</p>
<ul>
<li>podemos definir uma instruÃ§Ã£o para "resumir o catÃ¡logo de cursos para o outono de 2023"</li>
<li>podemos usar o conteÃºdo principal para fornecer alguns exemplos da saÃ­da desejada</li>
<li>podemos usar o conteÃºdo secundÃ¡rio para identificar as 5 principais "tags" de interesse.</li>
</ul>
<p>Agora, o modelo pode fornecer um resumo no formato mostrado pelos poucos exemplos - mas se um resultado tiver vÃ¡rias tags, pode priorizar as 5 tags identificadas no conteÃºdo secundÃ¡rio.</p>
<hr />
<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #3:
Prompt Engineering Techniques.
What are some basic techniques for prompt engineering?
Illustrate it with some exercises.
-->

<h2 id="melhores-praticas-para-prompts">Melhores PrÃ¡ticas para Prompts</h2>
<p>Agora que sabemos como os prompts podem ser <em>construÃ­dos</em>, podemos comeÃ§ar a pensar em como <em>projetÃ¡-los</em> para refletir as melhores prÃ¡ticas. Podemos pensar nisso em duas partes - ter a <em>mentalidade</em> certa e aplicar as <em>tÃ©cnicas</em> certas.</p>
<h3 id="mentalidade-de-engenharia-de-prompt">Mentalidade de Engenharia de Prompt</h3>
<p>A Engenharia de Prompt Ã© um processo de tentativa e erro, entÃ£o tenha em mente trÃªs fatores amplos:</p>
<ol>
<li>
<p><strong>Entender o DomÃ­nio Ã© Importante.</strong> A precisÃ£o e relevÃ¢ncia da resposta Ã© uma funÃ§Ã£o do <em>domÃ­nio</em> no qual a aplicaÃ§Ã£o ou usuÃ¡rio opera. Aplique sua intuiÃ§Ã£o e experiÃªncia de domÃ­nio para <strong>personalizar tÃ©cnicas</strong> ainda mais. Por exemplo, defina <em>personalidades especÃ­ficas do domÃ­nio</em> em seus prompts de sistema, ou use <em>modelos especÃ­ficos do domÃ­nio</em> em seus prompts de usuÃ¡rio. ForneÃ§a conteÃºdo secundÃ¡rio que reflita contextos especÃ­ficos do domÃ­nio, ou use <em>cues e exemplos especÃ­ficos do domÃ­nio</em> para orientar o modelo em direÃ§Ã£o a padrÃµes de uso familiares.</p>
</li>
<li>
<p><strong>Entender o Modelo Ã© Importante.</strong> Sabemos que os modelos sÃ£o estocÃ¡sticos por natureza. Mas as implementaÃ§Ãµes do modelo tambÃ©m podem variar em termos do conjunto de dados de treinamento que eles usam (conhecimento prÃ©-treinado), as capacidades que eles fornecem (por exemplo, via API ou SDK) e o tipo de conteÃºdo para o qual sÃ£o otimizados (por exemplo, cÃ³digo vs. imagens vs. texto). Compreenda as forÃ§as e limitaÃ§Ãµes do modelo que vocÃª estÃ¡ usando e use esse conhecimento para <em>priorizar tarefas</em> ou construir <em>modelos personalizados</em> otimizados para as capacidades do modelo.</p>
</li>
<li>
<p><strong>IteraÃ§Ã£o e ValidaÃ§Ã£o SÃ£o Importantes.</strong> Os modelos estÃ£o evoluindo rapidamente, e as tÃ©cnicas de engenharia de prompt tambÃ©m. Como especialista no domÃ­nio, vocÃª pode ter outros contextos ou critÃ©rios <em>especÃ­ficos de sua</em> aplicaÃ§Ã£o, que podem nÃ£o se aplicar Ã  comunidade em geral. Use ferramentas e tÃ©cnicas de engenharia de prompt para "iniciar" a construÃ§Ã£o do prompt, depois itere e valide os resultados usando sua prÃ³pria intuiÃ§Ã£o e experiÃªncia de domÃ­nio. Registre suas percepÃ§Ãµes e crie uma <strong>base de conhecimento</strong> (por exemplo, bibliotecas de prompts) que pode ser usada como uma nova linha de base por outras pessoas, para iteraÃ§Ãµes mais rÃ¡pidas no futuro.</p>
</li>
</ol>
<h2 id="melhores-praticas">Melhores PrÃ¡ticas</h2>
<p>Agora, vamos dar uma olhada nas prÃ¡ticas recomendadas comuns pela <a href="https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst">Open AI</a> e pelos praticantes da <a href="https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst">Azure OpenAI</a>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">What</th>
<th style="text-align: left;">Why</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Evaluate the latest models.</td>
<td style="text-align: left;">New model generations are likely to have improved features and quality - but may also incur higher costs. Evaluate them for impact, then make migration decisions.</td>
</tr>
<tr>
<td style="text-align: left;">Separate instructions &amp; context</td>
<td style="text-align: left;">Check if your model/provider defines <em>delimiters</em> to distinguish instructions, primary and secondary content more clearly. This can help models assign weights more accurately to tokens.</td>
</tr>
<tr>
<td style="text-align: left;">Be specific and clear</td>
<td style="text-align: left;">Give more details about the desired context, outcome, length, format, style etc. This will improve both the quality and consistency of responses. Capture recipes in reusable templates.</td>
</tr>
<tr>
<td style="text-align: left;">Be descriptive, use examples</td>
<td style="text-align: left;">Models may respond better to a "show and tell" approach. Start with a <code>zero-shot</code> approach where you give it an instruction (but no examples) then try <code>few-shot</code> as a refinement, providing a few examples of the desired output. Use analogies.</td>
</tr>
<tr>
<td style="text-align: left;">Use cues to jumpstart completions</td>
<td style="text-align: left;">Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.</td>
</tr>
<tr>
<td style="text-align: left;">Double Down</td>
<td style="text-align: left;">Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate &amp; validate to see what works.</td>
</tr>
<tr>
<td style="text-align: left;">Order Matters</td>
<td style="text-align: left;">The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.</td>
</tr>
<tr>
<td style="text-align: left;">Give the model an â€œoutâ€</td>
<td style="text-align: left;">Give the model a <em>fallback</em> completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or hallucinatory responses.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Como em qualquer prÃ¡tica recomendada, lembre-se de que <em>seus resultados podem variar</em> com base no modelo, na tarefa e no domÃ­nio. Use essas prÃ¡ticas como ponto de partida e itere para encontrar o que funciona melhor para vocÃª. Reavalie constantemente seu processo de engenharia de prompt Ã  medida que novos modelos e ferramentas se tornam disponÃ­veis, com foco na escalabilidade do processo e na qualidade das respostas.</p>
<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

<h2 id="tarefa">Tarefa</h2>
<p>ParabÃ©ns! VocÃª chegou ao final da liÃ§Ã£o! Ã‰ hora de colocar alguns desses conceitos e tÃ©cnicas Ã  prova com exemplos reais!</p>
<p>Para a nossa tarefa, usaremos um Jupyter Notebook com exercÃ­cios que vocÃª pode completar interativamente. VocÃª tambÃ©m pode estender o Notebook com suas prÃ³prias cÃ©lulas de Markdown e cÃ³digo para explorar ideias e tÃ©cnicas por conta prÃ³pria.</p>
<h3 id="para-comecar-faca-um-fork-do-repositorio-depois">Para comeÃ§ar, faÃ§a um fork do repositÃ³rio, depois</h3>
<ul>
<li>(Recomendado) Inicie o GitHub Codespaces</li>
<li>(Opcional) Clone o repositÃ³rio em seu dispositivo local e use-o com o Docker Desktop</li>
<li>(Opcional) Abra o Notebook com seu ambiente de execuÃ§Ã£o de notebook preferido.</li>
</ul>
<h3 id="em-seguida-configure-suas-variaveis-de-ambiente">Em seguida, configure suas variÃ¡veis de ambiente</h3>
<ul>
<li>Copie o arquivo <code>.env.copy</code> na raiz do repositÃ³rio para <code>.env</code> e preencha o valor <code>OPENAI_API_KEY</code>. VocÃª pode encontrar sua chave de API em seu <a href="https://beta.openai.com/account/api-keys?WT.mc_id=academic-105485-koreyst">OpenAI Dashboard</a>.</li>
</ul>
<h3 id="em-seguida-abra-o-jupyter-notebook">Em seguida, abra o Jupyter Notebook</h3>
<ul>
<li>Selecione o kernel de execuÃ§Ã£o. Se estiver usando as opÃ§Ãµes 1 ou 2, basta selecionar o kernel Python 3.10.x padrÃ£o fornecido pelo contÃªiner de desenvolvimento.</li>
</ul>
<p>VocÃª estÃ¡ pronto para executar os exercÃ­cios. Lembre-se de que nÃ£o hÃ¡ respostas <em>certas ou erradas</em> aqui - apenas explorando opÃ§Ãµes por tentativa e erro e construindo intuiÃ§Ã£o sobre o que funciona para um determinado modelo e domÃ­nio de aplicaÃ§Ã£o.</p>
<p><em>Por esse motivo, nÃ£o hÃ¡ segmentos de SoluÃ§Ã£o de CÃ³digo nesta liÃ§Ã£o. Em vez disso, o Notebook terÃ¡ cÃ©lulas de Markdown intituladas "Minha SoluÃ§Ã£o:" que mostram um exemplo de saÃ­da para referÃªncia.</em></p>
<!--
LESSON TEMPLATE:
Wrap the section with a summary and resources for self-guided learning.
-->

<h2 id="verificacao-de-conhecimento">VerificaÃ§Ã£o de Conhecimento</h2>
<p>Qual das seguintes opÃ§Ãµes seria uma boa instruÃ§Ã£o seguindo as melhores prÃ¡ticas razoÃ¡veis?</p>
<ol>
<li>Mostre-me uma imagem de um carro vermelho.</li>
<li>Mostre-me uma imagem de um carro vermelho da marca Volvo e modelo XC90 estacionado Ã  beira de um penhasco com o sol se pondo.</li>
<li>Mostre-me uma imagem de um carro vermelho da marca Volvo e modelo XC90.</li>
</ol>
<p><strong>Resposta:</strong> 2, Ã© a melhor instruÃ§Ã£o, pois fornece detalhes sobre "o que" e vai para especificidades (nÃ£o apenas qualquer carro, mas uma marca e modelo especÃ­ficos) e tambÃ©m descreve o ambiente geral. A opÃ§Ã£o 3 Ã© a prÃ³xima melhor, pois tambÃ©m contÃ©m muita descriÃ§Ã£o.</p>
<h2 id="desafio">ğŸš€ Desafio</h2>
<p>Veja se vocÃª consegue aproveitar a tÃ©cnica de "dica" com a instruÃ§Ã£o: Complete a frase "Mostre-me uma imagem de um carro vermelho da marca Volvo e ". O que ela responde e como vocÃª melhoraria?</p>
<h2 id="otimo-trabalho-continue-sua-aprendizagem">Ã“timo Trabalho! Continue Sua Aprendizagem</h2>
<p>Quer aprender mais sobre diferentes conceitos de Engenharia de InstruÃ§Ãµes? VÃ¡ para a <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">pÃ¡gina de aprendizado contÃ­nuo</a> para encontrar outros Ã³timos recursos sobre este tema.</p>
<p>Agora, vamos para a LiÃ§Ã£o 5, onde exploraremos <a href="../../../05-advanced-prompts/translations/pt-br/?WT.mc_id=academic-105485-koreyst">tÃ©cnicas avanÃ§adas de instruÃ§Ã£o</a>!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>