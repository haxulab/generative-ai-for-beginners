
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Mistral 모델로 빌드하기 - 面向初学者的生成式AI课程</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mistral" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="面向初学者的生成式AI课程" class="md-header__button md-logo" aria-label="面向初学者的生成式AI课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            面向初学者的生成式AI课程
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Mistral 모델로 빌드하기
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="面向初学者的生成式AI课程" class="md-nav__button md-logo" aria-label="面向初学者的生成式AI课程" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    面向初学者的生成式AI课程
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向初学者的生成式人工智能课程 ( Version 3 )
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../00-course-setup/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课程介绍和学习环境设置
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../01-introduction-to-genai/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第一章 : 生成式人工智能和 LLMs 介绍
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../02-exploring-and-comparing-different-llms/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第二章 : 探索和比较不同的 LLMs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../03-using-generative-ai-responsibly/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第三章 ： 负责任地使用生成式人工智能
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../04-prompt-engineering-fundamentals/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第四章：提示工程基础
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../05-advanced-prompts/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第五章：创建高级的提示工程技巧
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../06-text-generation-apps/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第六章：创建文本生成应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../07-building-chat-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第七章：创建聊天应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../08-building-search-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第八章：创建搜索应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../09-building-image-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第九章：构建图像生成应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../10-building-low-code-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十章：创建低代码的人工智能应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../11-integrating-with-function-calling/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十一章：为生成式 AI 添加 function calling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../12-designing-ux-for-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十二章：为人工智能应用程序添加用户体验
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../13-securing-ai-applications/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成式 AI 初学者指南：第 13 章 - 保护 AI 应用
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../14-the-generative-ai-application-lifecycle/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../15-rag-and-vector-databases/translations/cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    检索增强生成 (RAG) 与向量数据库
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../16-open-source-models/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../17-ai-agents/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../18-fine-tuning/translations/tw/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../19-slm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Small Language Models for Generative AI for Beginners
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building with Mistral Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../21-meta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building With the Meta Family Models
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      소개
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mistral_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral 모델들
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mistral-large-2-2407" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral Large 2 (2407)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mistral Large 2 (2407)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mistral-large-2-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral Large 2을 사용한 RAG 예제
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mistral-small" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral Small
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mistral-small-mistral-large" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral Small과 Mistral Large 비교
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mistral-nemo" class="md-nav__link">
    <span class="md-ellipsis">
      Mistral NeMo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenizer 비교
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      여기서 멈추지 말고, 더 깊이 탐구해 보세요
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="mistral">Mistral 모델로 빌드하기</h1>
<h2 id="_1">소개</h2>
<p>이 레슨에서는 다음의 내용을 다룹니다:
- 다양한 Mistral 모델 탐색
- 각 모델의 사용 사례와 시나리오 이해
- 각 모델의 고유한 기능을 보여주는 코드 예제</p>
<h2 id="mistral_1">Mistral 모델들</h2>
<p>이 레슨에서는 <strong>Mistral Large</strong>, <strong>Mistral Small</strong>, 그리고 <strong>Mistral Nemo</strong>라는 세 가지 Mistral 모델을 살펴보겠습니다.</p>
<p>세 모델 모두 Github Model 마켓플레이스에서 무료로 이용 가능합니다. 현 레슨에서는 이 세 모델들을 사용하여 코드를 실행할 예정입니다. Github Models를 사용하여 AI 모델로 프로토타입 제작에 대한 자세한 내용은 <a href="https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst">여기에서 확인할 수 있습니다.</a>. </p>
<h2 id="mistral-large-2-2407">Mistral Large 2 (2407)</h2>
<p>Mistral Large 2는 현재 Mistral의 대표 모델로, 기업용으로 설계되었습니다. </p>
<p>이 모델은 기존 Mistral Large 모델을 업그레이드한 것으로, 다음과 같은 개선 사항이 있습니다. </p>
<ul>
<li>더 큰 context window - 32k에서 128k로 확대</li>
<li>더 나아진 수학 및 코딩 작성 성능 - 평균 정확도가 60.4%에서 76.9%로 증가</li>
<li>더 향상된 다국어 성능 - 지원 언어에는 영어, 프랑스어, 독일어, 스페인어, 이탈리아어, 포르투갈어, 네덜란드어, 러시아어, 중국어, 일본어, 한국어, 아랍어, 힌디어가 포함</li>
</ul>
<p>이러한 기능을 통해 Mistral Large는 다음과 같은 분야에 적합합니다: 
- <em>검색 증강 생성(Retrieval Augmented Generation, RAG)</em> - 넓어진 context window 덕분에 더 나은 성능 발휘
- <em>함수 호출(Function Calling)</em> - 외부 도구와 API와의 통합을 가능하게 하는 네이티브 함수 호출 기능 제공. 해당 호출을 병렬 또는 순차적인 순서로 차례대로 수행 가능.
- <em>코드 생성(Code Generation)</em> - Python, Java, TypeScript, C++ 코드를 생성하는 데 우수한 성능을 발휘</p>
<h3 id="mistral-large-2-rag">Mistral Large 2을 사용한 RAG 예제</h3>
<p>이 예제에서는 Mistral Large 2를 사용해 텍스트 문서에 대한 RAG 패턴을 실행합니다. 질문은 한국어로 작성되었으며, 저자가 대학에 들어가기 전 했던 활동에 대해 묻고 있습니다. </p>
<p>Cohere Embeddings Model을 사용해 텍스트와 질문의 임베딩을 생성하며, faiss Python 패키지를 벡터 저장소로 사용합니다.</p>
<p>Mistral 모델에 보내는 프롬프트에는 질문과 유사한 검색 결과 청크들이 포함됩니다. 모델은 이 정보에 기반해 자연어 응답을 제공합니다. </p>
<pre><code class="language-python">pip install faiss-cpu
</code></pre>
<pre><code class="language-python">import requests
import numpy as np
import faiss
import os

from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential
from azure.ai.inference import EmbeddingsClient

endpoint = &quot;https://models.inference.ai.azure.com&quot;
model_name = &quot;Mistral-large&quot;
token = os.environ[&quot;GITHUB_TOKEN&quot;]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = requests.get('https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt')
text = response.text

chunk_size = 2048
chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]
len(chunks)

embed_model_name = &quot;cohere-embed-v3-multilingual&quot; 

embed_client = EmbeddingsClient(
        endpoint=endpoint,
        credential=AzureKeyCredential(token)
)

embed_response = embed_client.embed(
    input=chunks,
    model=embed_model_name
)



text_embeddings = []
for item in embed_response.data:
    length = len(item.embedding)
    text_embeddings.append(item.embedding)
text_embeddings = np.array(text_embeddings)


d = text_embeddings.shape[1]
index = faiss.IndexFlatL2(d)
index.add(text_embeddings)

question = &quot;저자가 대학에 오기 전에 주로 했던 두 가지 일은 무엇이었나요?？&quot;

question_embedding = embed_client.embed(
    input=[question],
    model=embed_model_name
)

question_embeddings = np.array(question_embedding.data[0].embedding)


D, I = index.search(question_embeddings.reshape(1, -1), k=2) # distance, index
retrieved_chunks = [chunks[i] for i in I.tolist()[0]]

prompt = f&quot;&quot;&quot;
Context information is below.
---------------------
{retrieved_chunks}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: {question}
Answer:
&quot;&quot;&quot;


chat_response = client.complete(
    messages=[
        SystemMessage(content=&quot;You are a helpful assistant.&quot;),
        UserMessage(content=prompt),
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=1000,
    model=model_name
)

print(chat_response.choices[0].message.content)
</code></pre>
<h2 id="mistral-small">Mistral Small</h2>
<p>Mistral Small은 Mistral 제품군 내의 프리미어/기업용 카테고리에 속한 또 다른 모델입니다. 이름에서 알 수 있듯이 소형 언어 모델(SLM)이죠. Mistral Small은 다음과 같은 장점이 있습니다:
- 비용 절감 - Mistral Large와 NeMo같은 Mistral LLMs에 비해 80% 비용 절감
- 짧은 지연 시간 - Mistral LLM에 비해 빠른 응답 속도
- 유연성 - 리소스 요구 사항이 적어 다양한 환경에서 배포 가능</p>
<p>Mistral Small은 다음과 같은 경우에 적합합니다:</p>
<ul>
<li>요약, 감정 분석, 번역 등 텍스트 기반 작업</li>
<li>비용 효율성으로 인해 자주 요청이 필요한 애플리케이션</li>
<li>즉각적인 응답이 필요한 코드 검토, 코드 제안 등의 작업</li>
</ul>
<h2 id="mistral-small-mistral-large">Mistral Small과 Mistral Large 비교</h2>
<p>아래 코드 셀을 실행하여 Mistral Small과 Large의 응답 시간 차이를 비교해보겠습니다. </p>
<p>실행해보면 동일한 프롬프트에 대해 3-5초 정도의 응답 시간 차이를 확인할 수 있으며, 응답 길이와 스타일 차이도 살펴볼 수 있습니다.</p>
<pre><code class="language-python">
import os 
endpoint = &quot;https://models.inference.ai.azure.com&quot;
model_name = &quot;Mistral-small&quot;
token = os.environ[&quot;GITHUB_TOKEN&quot;]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage(content=&quot;You are a helpful coding assistant.&quot;),
        UserMessage(content=&quot;Can you write a Python function to the fizz buzz test?&quot;),
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=1000,
    model=model_name
)

print(response.choices[0].message.content)

</code></pre>
<pre><code class="language-python">
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = &quot;https://models.inference.ai.azure.com&quot;
model_name = &quot;Mistral-large&quot;
token = os.environ[&quot;GITHUB_TOKEN&quot;]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage(content=&quot;You are a helpful coding assistant.&quot;),
        UserMessage(content=&quot;Can you write a Python function to the fizz buzz test?&quot;),
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=1000,
    model=model_name
)

print(response.choices[0].message.content)

</code></pre>
<h2 id="mistral-nemo">Mistral NeMo</h2>
<p>이 레슨에서 다루는 다른 두 모델과 비교하여 Mistral NeMo는 Apache2 라이선스를 가진 유일한 무료 모델입니다. </p>
<p>NeMo는 Mistral의 이전 오픈 소스 LLM인 Mistral 7B의 업그레이드된 모델로 볼 수 있습니다. </p>
<p>NeMo 모델의 특징은 다음과 같습니다:</p>
<ul>
<li>
<p><em>더 효율적인 토큰화</em> - tiktoken 대신 Tekken tokenizer를 사용해 더 많은 언어와 코드에서 더 나은 성능 발휘</p>
</li>
<li>
<p><em>파인튜닝</em> - 기본 모델은 파인튜닝이 가능하여, 파인튜닝이 필요한 사용 사례에 더 유연하게 활용할 수 있음</p>
</li>
<li>
<p><em>네이티브 함수 호출</em> - Mistral Large처럼 function calling에 대한 학습이 되어 있음. 오픈 소스 모델로서는 최초로 이 기능을 갖추었다는 점이 독특함</p>
</li>
</ul>
<h2 id="tokenizer">Tokenizer 비교</h2>
<p>다음 샘플에서는 Mistral NeMo가 Mistral Large와 비교하여 어떻게 tokenization을 처리하는지 살펴봅니다. </p>
<p>두 샘플 모두 동일한 프롬프트를 사용하지만, NeMo가 Mistral Large보다 적은 수의 토큰을 반환하는 것을 확인할 수 있습니다.</p>
<pre><code class="language-bash">pip install mistral-common
</code></pre>
<pre><code class="language-python"># 필요한 패키지 임포트:
from mistral_common.protocol.instruct.messages import (
    UserMessage,
)
from mistral_common.protocol.instruct.request import ChatCompletionRequest
from mistral_common.protocol.instruct.tool_calls import (
    Function,
    Tool,
)
from mistral_common.tokens.tokenizers.mistral import MistralTokenizer

# Mistral 토크나이저 로드

model_name = &quot;open-mistral-nemo &quot;

tokenizer = MistralTokenizer.from_model(model_name)

# 메시지 목록 토큰화
tokenized = tokenizer.encode_chat_completion(
    ChatCompletionRequest(
        tools=[
            Tool(
                function=Function(
                    name=&quot;get_current_weather&quot;,
                    description=&quot;Get the current weather&quot;,
                    parameters={
                        &quot;type&quot;: &quot;object&quot;,
                        &quot;properties&quot;: {
                            &quot;location&quot;: {
                                &quot;type&quot;: &quot;string&quot;,
                                &quot;description&quot;: &quot;The city and state, e.g. San Francisco, CA&quot;,
                            },
                            &quot;format&quot;: {
                                &quot;type&quot;: &quot;string&quot;,
                                &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;],
                                &quot;description&quot;: &quot;The temperature unit to use. Infer this from the users location.&quot;,
                            },
                        },
                        &quot;required&quot;: [&quot;location&quot;, &quot;format&quot;],
                    },
                )
            )
        ],
        messages=[
            UserMessage(content=&quot;What's the weather like today in Paris&quot;),
        ],
        model=model_name,
    )
)
tokens, text = tokenized.tokens, tokenized.text

# 토큰 수 세기
print(len(tokens))
</code></pre>
<pre><code class="language-python"># 필요한 패키지 임포트:
from mistral_common.protocol.instruct.messages import (
    UserMessage,
)
from mistral_common.protocol.instruct.request import ChatCompletionRequest
from mistral_common.protocol.instruct.tool_calls import (
    Function,
    Tool,
)
from mistral_common.tokens.tokenizers.mistral import MistralTokenizer

# Mistral 토크나이저 로드

model_name = &quot;mistral-large-latest&quot;

tokenizer = MistralTokenizer.from_model(model_name)

# 메시지 목록 토큰화
tokenized = tokenizer.encode_chat_completion(
    ChatCompletionRequest(
        tools=[
            Tool(
                function=Function(
                    name=&quot;get_current_weather&quot;,
                    description=&quot;Get the current weather&quot;,
                    parameters={
                        &quot;type&quot;: &quot;object&quot;,
                        &quot;properties&quot;: {
                            &quot;location&quot;: {
                                &quot;type&quot;: &quot;string&quot;,
                                &quot;description&quot;: &quot;The city and state, e.g. San Francisco, CA&quot;,
                            },
                            &quot;format&quot;: {
                                &quot;type&quot;: &quot;string&quot;,
                                &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;],
                                &quot;description&quot;: &quot;The temperature unit to use. Infer this from the users location.&quot;,
                            },
                        },
                        &quot;required&quot;: [&quot;location&quot;, &quot;format&quot;],
                    },
                )
            )
        ],
        messages=[
            UserMessage(content=&quot;What's the weather like today in Paris&quot;),
        ],
        model=model_name,
    )
)
tokens, text = tokenized.tokens, tokenized.text

# 토큰 수 세기
print(len(tokens))
</code></pre>
<h2 id="_2">여기서 멈추지 말고, 더 깊이 탐구해 보세요</h2>
<p>이 레슨을 마쳤다면, <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">생성형 AI 학습 컬렉션</a>에서 더 많은 내용을 확인하며 생성형 AI 지식을 한 단계 더 높여보세요!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>